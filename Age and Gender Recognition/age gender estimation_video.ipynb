{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"age gender estimation_video.ipynb","provenance":[],"authorship_tag":"ABX9TyMh2L0lqR/Aksz/uuwdZ2bu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CKn7oA5hdnNE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592068961370,"user_tz":-540,"elapsed":1122,"user":{"displayName":"송정현","photoUrl":"","userId":"03834848729540117659"}},"outputId":"2dbe3c9e-50b1-41ed-fa32-ab39f2e80207"},"source":["# 내 구글 드라이브 연동\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GI8XYNg0d0if","colab_type":"code","colab":{}},"source":["# 필요한 패키지와 모듈을 불러옴\n","import dlib\n","import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6-8hxJ0fM78","colab_type":"code","colab":{}},"source":["def DetectAndDisplay(image):\n","  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","  faces = detector(gray, 1)  # detector 에 의해 얼굴 감지\n","  print(\"Number of faces detected: {}\".format(len(faces)))\n","\n","  for face in faces:\n","    x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()  # boxing 좌표를 구한다.\n","\n","    face_img = image[y1:y2, x1:x2].copy()  # 이미지에서 얼굴 영역만 copy\n","\n","    blob = cv2.dnn.blobFromImage(face_img, scalefactor=1, size=(227, 227),\n","           mean=(78.4263377603, 87.7689143744, 114.895847746), swapRB=False, crop=False)\n","\n","    # predict age(나이를 예측합니다)\n","    age_detector.setInput(blob)\n","    age_preds = age_detector.forward()\n","    age = age_list[age_preds[0].argmax()]\n","\n","    # predict gender(성별을 예측합니다)\n","    gender_detector.setInput(blob)\n","    gender_preds = gender_detector.forward()\n","    gender = gender_list[gender_preds[0].argmax()]\n","\n","    cv2.rectangle(image, (x1, y1), (x2, y2), (255,255,255), 2)\n","    overlay_text = '%s %s' % (gender, age)\n","    cv2.putText(image, overlay_text, org=(x1+10, y1-10), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n","                fontScale=0.6, color=(0,0,0), thickness=10)\n","    cv2.putText(image, overlay_text, org=(x1+10, y1-10),\n","                fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.6, color=(255,255,255), thickness=2)\n","\n","  # video 를 disk 에 output 하기 위해 writer 를 초기화한다.\n","  global writer\n","  if writer is None and output_name is not None:\n","     fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n","     writer = cv2.VideoWriter(output_name, fourcc, 30,\n","                (image.shape[1], image.shape[0]), True)\n","\n","  # disk 에 frame 을 write 합니다.\n","  if writer is not None:\n","     writer.write(image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XUx0jvRGd0lG","colab_type":"code","colab":{}},"source":["age_list = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']  # 나이 분류 구간 정의\n","gender_list = ['Male','Female']  # 성별 구분 정의\n","\n","file_name = '1988.mp4'         # 원본 동영상 파일\n","output_name = 'age_gender_video.mp4' # 예측된 output 동영상 이름"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h4LjFHI6d0n2","colab_type":"code","colab":{}},"source":["detector = dlib.get_frontal_face_detector()       # 얼굴을 감지하는 detector 정의\n","\n","age_detector = cv2.dnn.readNetFromCaffe(          # 나이를 감지하는 detector 정의\n","               'gdrive/My Drive/CV/Age and Gender Recognition/deploy_age.prototxt', \n","               'gdrive/My Drive/CV/Age and Gender Recognition/age_net.caffemodel')\n","gender_detector = cv2.dnn.readNetFromCaffe(       # 성별을 감지하는 detector 정의\n","               'gdrive/My Drive/CV/Age and Gender Recognition/deploy_gender.prototxt', \n","               'gdrive/My Drive/CV/Age and Gender Recognition/gender_net.caffemodel')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HAQFhsi_d0qY","colab_type":"code","colab":{}},"source":["cap = cv2.VideoCapture(file_name)     # 동영상을 읽어옴\n","\n","# 원본 동영상이 오픈되는지 확인\n","writer = None\n","if not cap.isOpened:\n","    print('--(!)Error opening video capture')\n","    exit(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fePylmRUd0su","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592069102762,"user_tz":-540,"elapsed":102319,"user":{"displayName":"송정현","photoUrl":"","userId":"03834848729540117659"}},"outputId":"39281817-05c1-4127-a383-9a92e793b203"},"source":["while True:\n","  # 원본 동영상에서 frame 을 읽는다\n","  ret, image = cap.read()\n","\n","  # 원본 동영상에서 더 이상 frame 을 읽지 못했다면 Exit\n","  if image is None:\n","     # close the video file pointers\n","     cap.release()\n","     # close the writer point\n","     writer.release()\n","     print('--(!) No captured frame -- Break!')\n","     break\n","\n","  DetectAndDisplay(image)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","Number of faces detected: 1\n","--(!) No captured frame -- Break!\n"],"name":"stdout"}]}]}