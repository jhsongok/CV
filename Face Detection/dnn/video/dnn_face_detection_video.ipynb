{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dnn_face_detection_video.ipynb","provenance":[],"authorship_tag":"ABX9TyP6Ih1yRsPqDdTAWMEkIF8h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"HghQ2X9QXBLe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":128},"executionInfo":{"status":"ok","timestamp":1591535796940,"user_tz":-540,"elapsed":20274,"user":{"displayName":"송정현","photoUrl":"","userId":"03834848729540117659"}},"outputId":"d6ed6921-fe31-4a06-d777-b932605eb572"},"source":["# 내 구글 드라이브에 연동\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gQCcECj4X8xA","colab_type":"code","colab":{}},"source":["# 필요한 패키지와 모듈을 불러옴\n","import cv2\n","import numpy as np\n","import time\n","import io\n","import base64\n","from IPython.display import HTML"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NIc7qbYzYG56","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":344,"output_embedded_package_id":"1VqG1Wsrxm56KmZPPiLCnrsTNFKTQyFOq"},"executionInfo":{"status":"ok","timestamp":1591536630962,"user_tz":-540,"elapsed":17531,"user":{"displayName":"송정현","photoUrl":"","userId":"03834848729540117659"}},"outputId":"8f9e4e0b-e6b2-476c-df60-a6c30123ebe9"},"source":["# Detection 하기 전에 원본 동영상을 Display\n","video = io.open('gdrive/My Drive/CV/Face Detection/data/video/son.mp4', 'r+b').read()\n","encoded = base64.b64encode(video)\n","HTML(data='''<video width=\"50%\" controls>\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n","             </video>'''.format(encoded.decode('ascii')))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"71joDP5DXI_p","colab_type":"code","colab":{}},"source":["# dnn module의 위치 정의\n","model_name = 'gdrive/My Drive/CV/Face Detection/data/res10_300x300_ssd_iter_140000.caffemodel'   # caffemodel의 weight 값\n","prototxt_name = 'gdrive/My Drive/CV/Face Detection/data/deploy.prototxt.txt'                     # model Architecture 에 대한 정보                \n","min_confidence = 0.5  # detection 으로 인정할 최소 확률(신뢰도)\n","file_name = 'gdrive/My Drive/CV/Face Detection/data/video/son.mp4' # Detection 할 원본 동영상\n","output_name = 'output_video.mp4'    # detection 된 output 동영상"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z5HzSPwKXJCd","colab_type":"code","colab":{}},"source":["def detectAndDisplay(frame):\n","    # caffemodel의 weight 값과 모델 네트워크 구성을 불러와서 모델을 정의\n","    model = cv2.dnn.readNetFromCaffe(prototxt_name, model_name)\n","\n","    # 이미지를 300x300 으로 size를 조정하고 blob 를 만든다.\n","    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,\n","            (300, 300), (104.0, 177.0, 123.0))\n","\n","    model.setInput(blob)\n","    detections = model.forward()\n","    \n","    # detections 한 수만큼 루프가 돈다.\n","    for i in range(0, detections.shape[2]):\n","            confidence = detections[0, 0, i, 2]  # confidence 는 detection한 확률을 나타냄\n","\n","            # min_confidence 보다 큰 경우에만 detection 으로 인정함\n","            if confidence > min_confidence:\n","                    (height, width) = frame.shape[:2]\n","                    # detection 된 영역을 boxing\n","                    # 상대적 좌표 * np.array([width, height, width, height]) 절대적인 boxing 좌표을 구해낸다. \n","                    box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n","                    (startX, startY, endX, endY) = box.astype(\"int\")\n","     \n","                    # 얼굴에 bounding box(사각형)를 그리고 확률값도 함께 나타낸다\n","                    text = \"{:.2f}%\".format(confidence * 100)\n","                    y = startY - 10 if startY - 10 > 10 else startY + 10\n","                    cv2.rectangle(frame, (startX, startY), (endX, endY),\n","                            (0, 255, 0), 2)\n","                    cv2.putText(frame, text, (startX, y),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n","\n","    # video 를 disk 에 output 하기 위해 writer 를 초기화한다.\n","    global writer\n","    if writer is None and output_name is not None:\n","        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n","        writer = cv2.VideoWriter(output_name, fourcc, 30,\n","                (frame.shape[1], frame.shape[0]), True)\n","        \n","    # disk 에 frame 을 write 합니다.\n","    if writer is not None:\n","        writer.write(frame)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_VDr7lFWXJE2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1591536697443,"user_tz":-540,"elapsed":24106,"user":{"displayName":"송정현","photoUrl":"","userId":"03834848729540117659"}},"outputId":"600f6665-2da1-4f09-8960-80769f2965e5"},"source":["# 원본 동영상에서 video stream을 읽어온다.\n","cap = cv2.VideoCapture(file_name)\n","writer = None\n","if not cap.isOpened:\n","    print('--(!)Error opening video capture')\n","    exit(0)\n","while True:\n","    ret, frame = cap.read()\n","    if frame is None:\n","        # close the video file pointers\n","        cap.release()\n","        # close the writer point\n","        writer.release()\n","        print('--(!) No captured frame -- Break!')\n","        break\n","    detectAndDisplay(frame)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--(!) No captured frame -- Break!\n"],"name":"stdout"}]}]}